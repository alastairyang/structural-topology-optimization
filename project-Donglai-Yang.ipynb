{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64684aea",
   "metadata": {},
   "source": [
    "# AE Structural Optimization Final Project: topology optimization\n",
    "## Author: Donglai Yang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4511cf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from scipy import spatial\n",
    "from scipy.sparse import linalg\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib.tri as tri\n",
    "\n",
    "class MMA:\n",
    "    def __init__(self, n, m, x_init, lb, ub, objfunc, gradfunc):\n",
    "        \"\"\"\n",
    "        Method of moving asymptotes (MMA) optimizer\n",
    "\n",
    "        Parameters:\n",
    "            n: number of design variables\n",
    "            m: number of constraints\n",
    "            x_init: initial design variable values\n",
    "            lb: lower bounds on design variables\n",
    "            ub: upper bounds on design variables\n",
    "            objfunc: function that computes the objective and constraint values\n",
    "            gradfunc: function that computes the objective and constraint gradients\n",
    "        \"\"\"\n",
    "\n",
    "        self.n = n\n",
    "        self.m = m\n",
    "\n",
    "        self.lb = lb\n",
    "        self.ub = ub\n",
    "        self.objfunc = objfunc\n",
    "        self.gradfunc = gradfunc\n",
    "\n",
    "        self.mma_iter = 0\n",
    "\n",
    "        # Allocate space for the design variables\n",
    "        self.x = np.zeros(self.n)\n",
    "        self.x1 = np.zeros(self.n)\n",
    "        self.x2 = np.zeros(self.n)\n",
    "\n",
    "        # Set the initial design point\n",
    "        self.x[:] = x_init[:]\n",
    "\n",
    "        # The objective and constraint functions\n",
    "        self.c = np.zeros(self.m)\n",
    "        self.g = np.zeros(self.n)\n",
    "        self.A = np.zeros((self.m, self.n))\n",
    "\n",
    "        self.b = np.zeros(self.m)\n",
    "        self.L = np.zeros(self.n)\n",
    "        self.U = np.zeros(self.n)\n",
    "        self.alpha = np.zeros(self.n)\n",
    "        self.beta = np.zeros(self.n)\n",
    "\n",
    "        self.p = np.zeros((self.m + 1, self.n))\n",
    "        self.q = np.zeros((self.m + 1, self.n))\n",
    "\n",
    "        # Set the optimization parameters\n",
    "        self.move_limit = 0.5\n",
    "        self.init_asymptote_offset = 0.1\n",
    "        self.asymptote_relax = 1.2\n",
    "        self.asymptote_contract = 0.7\n",
    "        self.min_asymptote_offset = 1e-3\n",
    "        self.max_asymptote_offset = 10.0\n",
    "        self.eps_regularization = 0.0  # 1e-5\n",
    "        self.delta_regularization = 0.0  # 1e-3\n",
    "\n",
    "    def update_asymptotes(self):\n",
    "        lower = np.maximum(self.lb, self.x - self.move_limit)\n",
    "        upper = np.minimum(self.ub, self.x + self.move_limit)\n",
    "        diff = upper - lower\n",
    "\n",
    "        if self.mma_iter < 2:\n",
    "            self.L = self.x - self.init_asymptote_offset * diff\n",
    "            self.U = self.x + self.init_asymptote_offset * diff\n",
    "        else:\n",
    "            # Compute the product of the difference of the two previous\n",
    "            # updates to determine how to update the move limits. If the\n",
    "            # signs are different, then indc < 0.0 and we contract the\n",
    "            # asymptotes, otherwise we expand the asymptotes.\n",
    "            indc = (self.x - self.x1) * (self.x1 - self.x2)\n",
    "\n",
    "            # Compute the interval length\n",
    "            intrvl = np.maximum(diff, 0.01)\n",
    "            intrvl = np.minimum(intrvl, 100.0)\n",
    "\n",
    "            # Select contraction or relaxation factors per index\n",
    "            mask = indc < 0.0\n",
    "            scale = np.where(mask, self.asymptote_contract, self.asymptote_relax)\n",
    "\n",
    "            # Update the asymtotes\n",
    "            self.L = self.x - scale * (self.x1 - self.L)\n",
    "            self.U = self.x + scale * (self.U - self.x1)\n",
    "\n",
    "            # Ensure that the asymptotes do not converge entirely on the design\n",
    "            # variable value\n",
    "            self.L = np.minimum(self.L, self.x - self.min_asymptote_offset * intrvl)\n",
    "            self.U = np.maximum(self.U, self.x + self.min_asymptote_offset * intrvl)\n",
    "\n",
    "            # Enforce a maximum offset so that the asymptotes do not move too far\n",
    "            # away from the design variables\n",
    "            self.L = np.maximum(self.L, self.x - self.max_asymptote_offset * intrvl)\n",
    "            self.U = np.minimum(self.U, self.x + self.max_asymptote_offset * intrvl)\n",
    "\n",
    "        # Compute the differences\n",
    "        Ux = self.U - self.x\n",
    "        xL = self.x - self.L\n",
    "\n",
    "        # Compute the lower and upper bounds\n",
    "        self.alpha = np.maximum(lower, 0.9 * self.L + 0.1 * self.x, self.x - 0.5 * diff)\n",
    "        self.beta = np.minimum(upper, 0.9 * self.U + 0.1 * self.x, self.x + 0.5 * diff)\n",
    "\n",
    "        # Compute the MMA coefficients for the objective\n",
    "        eps = self.eps_regularization\n",
    "        delta = self.delta_regularization\n",
    "        gpos = np.maximum(self.g, 0.0)\n",
    "        gneg = np.maximum(-self.g, 0.0)\n",
    "        gpos_reg = (1.0 + delta) * gpos + delta * gneg + eps / (self.U - self.L)\n",
    "        gneg_reg = (1.0 + delta) * gneg + delta * gpos + eps / (self.U - self.L)\n",
    "\n",
    "        # Update p and q for the objective\n",
    "        self.p[0, :] = gpos_reg * Ux**2\n",
    "        self.q[0, :] = gneg_reg * xL**2\n",
    "\n",
    "        # Update p and q for the constraints\n",
    "        gpos = np.maximum(self.A, 0.0)\n",
    "        gneg = np.maximum(-self.A, 0.0)\n",
    "        self.p[1:, :] = gpos * Ux**2\n",
    "        self.q[1:, :] = gneg * xL**2\n",
    "\n",
    "        # Compute the b right-hand-side for the constraints\n",
    "        self.b[:] = -self.c\n",
    "        self.b[:] += np.sum(self.p[1:, :] / Ux, axis=1)\n",
    "        self.b[:] += np.sum(self.q[1:, :] / xL, axis=1)\n",
    "\n",
    "        return\n",
    "\n",
    "    def compute_design_from_dual(self, y):\n",
    "        \"\"\"Compute the design variables from the dual variables\"\"\"\n",
    "\n",
    "        # Convenience variable y0 = [1.0, y[0], y[1], ..., y[m-1]]\n",
    "        y0 = np.ones(self.m + 1)\n",
    "        y0[1:] = y[:]\n",
    "\n",
    "        # Compute the design variables as a function of the dual variables x(y)\n",
    "        a = np.sqrt(self.p.T @ y0)\n",
    "        b = np.sqrt(self.q.T @ y0)\n",
    "\n",
    "        return np.clip((a * self.L + b * self.U) / (a + b), self.alpha, self.beta)\n",
    "\n",
    "    def dual_objective(self, y):\n",
    "        x0 = self.compute_design_from_dual(y)\n",
    "\n",
    "        y0 = np.ones(self.m + 1)\n",
    "        y0[1:] = y[:]\n",
    "\n",
    "        # Compute the dual objective function\n",
    "        Ux = self.U - x0\n",
    "        xL = x0 - self.L\n",
    "        obj = np.sum((self.p.T @ y0) / Ux + (self.q.T @ y0) / xL) - np.dot(y, self.b)\n",
    "\n",
    "        # Return the negative of the dual objective since we want\n",
    "        # to maximize the objective function\n",
    "        return -1.0 * obj\n",
    "\n",
    "    def dual_gradient(self, y):\n",
    "        x0 = self.compute_design_from_dual(y)\n",
    "\n",
    "        # Initialize the gradient\n",
    "        g = np.zeros(self.m)\n",
    "        g[:] = -self.b\n",
    "\n",
    "        Ux = self.U - x0\n",
    "        xL = x0 - self.L\n",
    "        g[:] += np.sum(self.p[1:, :] / Ux[np.newaxis, :], axis=1)\n",
    "        g[:] += np.sum(self.q[1:, :] / xL[np.newaxis, :], axis=1)\n",
    "\n",
    "        return -g\n",
    "\n",
    "    def solve_dual_problem(self):\n",
    "\n",
    "        # Define the initial point\n",
    "        y_init = np.ones(self.m)\n",
    "\n",
    "        # Define bounds: x >= 0\n",
    "        bounds = [(0, None)] * self.m\n",
    "\n",
    "        # Run optimization\n",
    "        res = minimize(\n",
    "            self.dual_objective,\n",
    "            y_init,\n",
    "            bounds=bounds,\n",
    "            method=\"L-BFGS-B\",\n",
    "        )\n",
    "\n",
    "        if not res.success:\n",
    "            print(\"MMA subproblem optimization failed\")\n",
    "            return np.zeros(self.m)\n",
    "\n",
    "        return res.x\n",
    "\n",
    "    def update(self):\n",
    "        fobj, con = self.objfunc(self.x) \n",
    "        print(\"self.c shape:\", self.c.shape, \" con shape:\", np.array(con).shape)\n",
    "        self.c[:] = con[:] # constraint values\n",
    "\n",
    "        grad, jac = self.gradfunc(self.x)\n",
    "        print(\"self.g shape:\", self.g.shape, \" grad shape:\", grad.shape)\n",
    "        print(\"self.A shape:\", self.A.shape, \" jac shape:\", jac.shape)\n",
    "        self.g[:] = grad[:] # gradient of objective\n",
    "        self.A[:] = jac # gradient of constraints\n",
    "\n",
    "        # Update the asymptotes\n",
    "        self.update_asymptotes()\n",
    "\n",
    "        # Solve the dual subproblem\n",
    "        y = self.solve_dual_problem()\n",
    "\n",
    "        # Update the design variables\n",
    "        self.x2[:] = self.x1[:]\n",
    "        self.x1[:] = self.x[:]\n",
    "        self.x[:] = self.compute_design_from_dual(y)\n",
    "\n",
    "        self.mma_iter += 1\n",
    "\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d64f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements: 6250\n",
      "Number of nodes: 6426\n"
     ]
    }
   ],
   "source": [
    "def eval_shape_funcs(eta, xi):\n",
    "    \"\"\"\n",
    "    Evaluate the shape functions and their derivatives\n",
    "    \"\"\"\n",
    "\n",
    "    N = 0.25 * np.array(\n",
    "        [\n",
    "            (1.0 - xi) * (1.0 - eta),\n",
    "            (1.0 + xi) * (1.0 - eta),\n",
    "            (1.0 + xi) * (1.0 + eta),\n",
    "            (1.0 - xi) * (1.0 + eta),\n",
    "        ]\n",
    "    )\n",
    "    Nxi = 0.25 * np.array([-(1.0 - eta), (1.0 - eta), (1.0 + eta), -(1.0 + eta)])\n",
    "    Neta = 0.25 * np.array([-(1.0 - xi), -(1.0 + xi), (1.0 + xi), (1.0 - xi)])\n",
    "\n",
    "    return N, Nxi, Neta\n",
    "\n",
    "\n",
    "def eval_shape_funcs_gradient(xi, eta, xe, ye):\n",
    "    \"\"\"\n",
    "    Evaluate the derivative of the shape functions in the physical\n",
    "    coordinate system by applying the Jacobian transformation\n",
    "    \"\"\"\n",
    "\n",
    "    N, Nxi, Neta = eval_shape_funcs(eta, xi)\n",
    "\n",
    "    # Store the Jacobian and the inverse of the Jacobian\n",
    "    nelems = xe.shape[0]\n",
    "    J = np.zeros((nelems, 2, 2))\n",
    "    invJ = np.zeros(J.shape)\n",
    "\n",
    "    # Compute the Jacobian transformation at each quadrature points\n",
    "    J[:, 0, 0] = np.dot(xe, Nxi)\n",
    "    J[:, 1, 0] = np.dot(ye, Nxi)\n",
    "    J[:, 0, 1] = np.dot(xe, Neta)\n",
    "    J[:, 1, 1] = np.dot(ye, Neta)\n",
    "\n",
    "    # Compute the inverse of the Jacobian\n",
    "    detJ = J[:, 0, 0] * J[:, 1, 1] - J[:, 0, 1] * J[:, 1, 0]\n",
    "    invJ[:, 0, 0] = J[:, 1, 1] / detJ\n",
    "    invJ[:, 0, 1] = -J[:, 0, 1] / detJ\n",
    "    invJ[:, 1, 0] = -J[:, 1, 0] / detJ\n",
    "    invJ[:, 1, 1] = J[:, 0, 0] / detJ\n",
    "\n",
    "    # Compute the derivative of the shape functions w.r.t. xi and eta\n",
    "    # [Nx, Ny] = [Nxi, Neta]*invJ\n",
    "    Nx = np.outer(invJ[:, 0, 0], Nxi) + np.outer(invJ[:, 1, 0], Neta)\n",
    "    Ny = np.outer(invJ[:, 0, 1], Nxi) + np.outer(invJ[:, 1, 1], Neta)\n",
    "\n",
    "    return detJ, Nx, Ny\n",
    "\n",
    "\n",
    "class NodeFilter:\n",
    "    \"\"\"\n",
    "    A node-based filter for topology optimization\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, conn, X, r0=1.0, ftype=\"spatial\", beta=10.0, eta=0.5, projection=False\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Create a filter\n",
    "        \"\"\"\n",
    "        self.conn = np.array(conn)\n",
    "        self.X = np.array(X)\n",
    "        self.nelems = self.conn.shape[0]\n",
    "        self.nnodes = int(np.max(self.conn)) + 1\n",
    "\n",
    "        # Store information about the projection\n",
    "        self.beta = beta\n",
    "        self.eta = eta\n",
    "        self.projection = projection\n",
    "\n",
    "        # Store information about the filter\n",
    "        self.F = None\n",
    "        self.A = None\n",
    "        self.B = None\n",
    "        if ftype == \"spatial\":\n",
    "            self._initialize_spatial(r0)\n",
    "        else:\n",
    "            self._initialize_helmholtz(r0)\n",
    "\n",
    "        return\n",
    "\n",
    "    def _initialize_spatial(self, r0):\n",
    "        \"\"\"\n",
    "        Initialize the spatial filter\n",
    "        \"\"\"\n",
    "\n",
    "        # Create a KD tree\n",
    "        tree = spatial.KDTree(self.X)\n",
    "\n",
    "        F = sparse.lil_matrix((self.nnodes, self.nnodes))\n",
    "        for i in range(self.nnodes):\n",
    "            indices = tree.query_ball_point(self.X[i, :], r0)\n",
    "            Fhat = np.zeros(len(indices))\n",
    "\n",
    "            for j, index in enumerate(indices):\n",
    "                dist = np.sqrt(\n",
    "                    np.dot(\n",
    "                        self.X[i, :] - self.X[index, :], self.X[i, :] - self.X[index, :]\n",
    "                    )\n",
    "                )\n",
    "                Fhat[j] = r0 - dist\n",
    "\n",
    "            Fhat = Fhat / np.sum(Fhat)\n",
    "            F[i, indices] = Fhat\n",
    "\n",
    "        self.F = F.tocsr()\n",
    "        self.FT = self.F.transpose()\n",
    "\n",
    "        return\n",
    "\n",
    "    def _initialize_helmholtz(self, r0):\n",
    "        i = []\n",
    "        j = []\n",
    "        for index in range(self.nelems):\n",
    "            for ii in self.conn[index, :]:\n",
    "                for jj in self.conn[index, :]:\n",
    "                    i.append(ii)\n",
    "                    j.append(jj)\n",
    "\n",
    "        # Convert the lists into numpy arrays\n",
    "        i_index = np.array(i, dtype=int)\n",
    "        j_index = np.array(j, dtype=int)\n",
    "\n",
    "        # Quadrature points\n",
    "        gauss_pts = [-1.0 / np.sqrt(3.0), 1.0 / np.sqrt(3.0)]\n",
    "\n",
    "        # Assemble all of the the 4 x 4 element stiffness matrices\n",
    "        Ae = np.zeros((self.nelems, 4, 4))\n",
    "        Ce = np.zeros((self.nelems, 4, 4))\n",
    "\n",
    "        Be = np.zeros((self.nelems, 2, 4))\n",
    "        He = np.zeros((self.nelems, 1, 4))\n",
    "\n",
    "        # Compute the x and y coordinates of each element\n",
    "        xe = self.X[self.conn, 0]\n",
    "        ye = self.X[self.conn, 1]\n",
    "\n",
    "        for j in range(2):\n",
    "            for i in range(2):\n",
    "                xi = gauss_pts[i]\n",
    "                eta = gauss_pts[j]\n",
    "                # Evaluate the gradient of the shape functions in physical coordinates\n",
    "                N, Nxi, Neta = eval_shape_funcs(xi, eta)\n",
    "                detJ, Nx, Ny = eval_shape_funcs_gradient(xi, eta, xe, ye)\n",
    "\n",
    "                # Set the B matrix for each element\n",
    "                He[:, 0, :] = N\n",
    "                Be[:, 0, :] = Nx\n",
    "                Be[:, 1, :] = Ny\n",
    "\n",
    "                Ce += np.einsum(\"n,nij,nil -> njl\", detJ, He, He)\n",
    "                Ae += np.einsum(\"n,nij,nil -> njl\", detJ * r0**2, Be, Be)\n",
    "\n",
    "        # Finish the computation of the Ae matrices\n",
    "        Ae += Ce\n",
    "\n",
    "        A = sparse.coo_matrix((Ae.flatten(), (i_index, j_index)))\n",
    "        A = A.tocsc()\n",
    "        self.A = linalg.factorized(A)\n",
    "\n",
    "        B = sparse.coo_matrix((Ce.flatten(), (i_index, j_index)))\n",
    "        self.B = B.tocsr()\n",
    "        self.BT = self.B.transpose()\n",
    "\n",
    "        return\n",
    "\n",
    "    def apply_filter(self, x):\n",
    "        if self.F is not None:\n",
    "            rho = self.F @ x\n",
    "        else:\n",
    "            rho = self.A(self.B.dot(x))\n",
    "\n",
    "        if self.projection:\n",
    "            denom = np.tanh(self.beta * self.eta) + np.tanh(\n",
    "                self.beta * (1.0 - self.eta)\n",
    "            )\n",
    "            rho = (\n",
    "                np.tanh(self.beta * self.eta) + np.tanh(self.beta * (rho - self.eta))\n",
    "            ) / denom\n",
    "\n",
    "        return rho\n",
    "\n",
    "    def apply_filter_gradient(self, g, x=None):\n",
    "        if self.projection:\n",
    "            if self.F is not None:\n",
    "                rho = self.F @ x\n",
    "            else:\n",
    "                rho = self.A(self.B.dot(x))\n",
    "\n",
    "            denom = np.tanh(self.beta * self.eta) + np.tanh(\n",
    "                self.beta * (1.0 - self.eta)\n",
    "            )\n",
    "            grad = (\n",
    "                (self.beta / denom) * 1.0 / np.cosh(self.beta * (rho - self.eta)) ** 2\n",
    "            ) * g\n",
    "        else:\n",
    "            grad = g\n",
    "\n",
    "        if self.F is not None:\n",
    "            return self.FT @ grad\n",
    "        else:\n",
    "            return self.BT.dot(self.A(grad))\n",
    "\n",
    "    def plot(self, u, ax=None, **kwargs):\n",
    "        \"\"\"\n",
    "        Create a plot\n",
    "        \"\"\"\n",
    "\n",
    "        # Create the triangles\n",
    "        triangles = np.zeros((2 * self.nelems, 3), dtype=int)\n",
    "        triangles[: self.nelems, 0] = self.conn[:, 0]\n",
    "        triangles[: self.nelems, 1] = self.conn[:, 1]\n",
    "        triangles[: self.nelems, 2] = self.conn[:, 2]\n",
    "\n",
    "        triangles[self.nelems :, 0] = self.conn[:, 0]\n",
    "        triangles[self.nelems :, 1] = self.conn[:, 2]\n",
    "        triangles[self.nelems :, 2] = self.conn[:, 3]\n",
    "\n",
    "        # Create the triangulation object\n",
    "        tri_obj = tri.Triangulation(self.X[:, 0], self.X[:, 1], triangles)\n",
    "\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots()\n",
    "\n",
    "        # Set the aspect ratio equal\n",
    "        ax.set_aspect(\"equal\")\n",
    "\n",
    "        # Create the contour plot\n",
    "        ax.tricontourf(tri_obj, u, **kwargs)\n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "class PlaneStress:\n",
    "    def __init__(\n",
    "        self, conn, X, bcs, forces={}, E=10.0, nu=0.3, rho=1.0, p=3.0, fltr=None\n",
    "    ):\n",
    "        self.conn = np.array(conn)\n",
    "        self.X = np.array(X)\n",
    "\n",
    "        self.nelems = self.conn.shape[0]\n",
    "        self.nnodes = int(np.max(self.conn)) + 1\n",
    "        self.nvars = 2 * self.nnodes\n",
    "\n",
    "        # Compute the constitutivve matrix\n",
    "        self.C = E * np.array(\n",
    "            [[1.0, nu, 0.0], [nu, 1.0, 0.0], [0.0, 0.0, 0.5 * (1.0 - nu)]]\n",
    "        )\n",
    "        self.C *= 1.0 / (1.0 - nu**2)\n",
    "        self.rho = rho\n",
    "        self.p = p\n",
    "\n",
    "        # Set the filter\n",
    "        self.fltr = fltr\n",
    "\n",
    "        self.reduced = self._compute_reduced_variables(self.nvars, bcs)\n",
    "        self.f = self._compute_forces(self.nvars, forces)\n",
    "\n",
    "        # Compute the x and y coordinates of each element\n",
    "        self.xe = self.X[self.conn, 0]\n",
    "        self.ye = self.X[self.conn, 1]\n",
    "\n",
    "        # Set the quadrature points\n",
    "        self.gauss_pts = [-1.0 / np.sqrt(3.0), 1.0 / np.sqrt(3.0)]\n",
    "\n",
    "        # Set up the i-j indices for the matrix - these are the row\n",
    "        # and column indices in the stiffness matrix\n",
    "        self.var = np.zeros((self.conn.shape[0], 8), dtype=int)\n",
    "        self.var[:, ::2] = 2 * self.conn\n",
    "        self.var[:, 1::2] = 2 * self.conn + 1\n",
    "\n",
    "        i = []\n",
    "        j = []\n",
    "        for index in range(self.nelems):\n",
    "            for ii in self.var[index, :]:\n",
    "                for jj in self.var[index, :]:\n",
    "                    i.append(ii)\n",
    "                    j.append(jj)\n",
    "\n",
    "        # Convert the lists into numpy arrays\n",
    "        self.i = np.array(i, dtype=int)\n",
    "        self.j = np.array(j, dtype=int)\n",
    "\n",
    "    def _compute_reduced_variables(self, nvars, bcs):\n",
    "        \"\"\"\n",
    "        Compute the reduced set of variables\n",
    "        \"\"\"\n",
    "        reduced = list(range(nvars))\n",
    "\n",
    "        # For each node that is in the boundary condition dictionary\n",
    "        for node in bcs:\n",
    "            uv_list = bcs[node]\n",
    "\n",
    "            # For each index in the boundary conditions (corresponding to\n",
    "            # either a constraint on u and/or constraint on v\n",
    "            for index in uv_list:\n",
    "                var = 2 * node + index\n",
    "                reduced.remove(var)\n",
    "\n",
    "        return reduced\n",
    "\n",
    "    def _compute_forces(self, nvars, forces):\n",
    "        \"\"\"\n",
    "        Unpack the dictionary containing the forces\n",
    "        \"\"\"\n",
    "        f = np.zeros(nvars)\n",
    "\n",
    "        for node in forces:\n",
    "            f[2 * node] += forces[node][0]\n",
    "            f[2 * node + 1] += forces[node][1]\n",
    "\n",
    "        return f\n",
    "\n",
    "    def assemble_stiffness_matrix(self, rhoE):\n",
    "        \"\"\"\n",
    "        Assemble the stiffness matrix\n",
    "        \"\"\"\n",
    "\n",
    "        # Assemble all of the the 8 x 8 element stiffness matrix\n",
    "        Ke = np.zeros((self.nelems, 8, 8))\n",
    "        Be = np.zeros((self.nelems, 3, 8))\n",
    "\n",
    "        for j in range(2):\n",
    "            for i in range(2):\n",
    "                xi = self.gauss_pts[i]\n",
    "                eta = self.gauss_pts[j]\n",
    "\n",
    "                # Evaluate the gradient of the shape functions in physical coordinates\n",
    "                detJ, Nx, Ny = eval_shape_funcs_gradient(xi, eta, self.xe, self.ye)\n",
    "\n",
    "                # Set the B matrix for each element\n",
    "                Be[:, 0, ::2] = Nx\n",
    "                Be[:, 1, 1::2] = Ny\n",
    "                Be[:, 2, ::2] = Ny\n",
    "                Be[:, 2, 1::2] = Nx\n",
    "\n",
    "                # This is a fancy (and fast) way to compute the element matrices\n",
    "                scale = detJ * (rhoE**self.p)\n",
    "                Ke += np.einsum(\"n,nij,ik,nkl -> njl\", scale, Be, self.C, Be)\n",
    "\n",
    "                # This is a slower way to compute the element matrices\n",
    "                # for k in range(self.nelems):\n",
    "                #     Ke[k, :, :] += detJ[k]*np.dot(Be[k, :, :].T, np.dot(self.C, Be[k, :, :]))\n",
    "\n",
    "        K = sparse.coo_matrix((Ke.flatten(), (self.i, self.j)))\n",
    "        K = K.tocsr()\n",
    "\n",
    "        return K\n",
    "\n",
    "    def assemble_mass_matrix(self, rhoE):\n",
    "        \"\"\"\n",
    "        Assemble the mass matrix for plane stress problem\n",
    "\n",
    "        This is modified from the function in 'Intro to Finite Element methods' lecture notes\n",
    "        \"\"\"\n",
    "\n",
    "        # Assemble all of the the 8 x 8 element mass matrices\n",
    "        Me = np.zeros((self.nelems, 8, 8))\n",
    "        He = np.zeros((self.nelems, 2, 8))\n",
    "\n",
    "        for j in range(2):\n",
    "            for i in range(2):\n",
    "                xi = self.gauss_pts[i]\n",
    "                eta = self.gauss_pts[j]\n",
    "\n",
    "                # Evaluate the shape functions\n",
    "                N, _, _ = eval_shape_funcs(xi, eta)\n",
    "\n",
    "                # Evaluate the gradient of the shape functions in physical coordinates\n",
    "                detJ, _, _ = eval_shape_funcs_gradient(xi, eta, self.xe, self.ye)\n",
    "\n",
    "                # Set the B matrix for each element\n",
    "                He[:, 0, ::2] = N\n",
    "                He[:, 1, 1::2] = N\n",
    "\n",
    "                # This is a fancy (and fast) way to compute the element matrices\n",
    "                scale = detJ * (rhoE**self.p)\n",
    "                Me += self.rho*np.einsum('n,nij,nil -> njl', scale, He, He)\n",
    "\n",
    "        M = sparse.coo_matrix((Me.flatten(), (self.i, self.j)))\n",
    "        M = M.tocsr()\n",
    "\n",
    "        return M\n",
    "\n",
    "    def stiffness_matrix_derivative(self, u, v):\n",
    "        \"\"\"\n",
    "        Compute u^{T}*dK/drhoE*v\n",
    "\n",
    "        This is provided at the end of 'topology optimization' lecture notes\n",
    "        \"\"\"\n",
    "\n",
    "        # Set the derivative we're about to compute\n",
    "        dfdrhoE = np.zeros(self.nelems)\n",
    "\n",
    "        # Assemble all of the the 8 x 8 element stiffness matrix\n",
    "        Be = np.zeros((self.nelems, 3, 8))\n",
    "\n",
    "        for j in range(2):\n",
    "            for i in range(2):\n",
    "                xi = self.gauss_pts[i]\n",
    "                eta = self.gauss_pts[j]\n",
    "\n",
    "                # Evaluate the gradient of the shape functions in physical coordinates\n",
    "                detJ, Nx, Ny = eval_shape_funcs_gradient(xi, eta, self.xe, self.ye)\n",
    "\n",
    "                # Set the B matrix for each element\n",
    "                Be[:, 0, ::2] = Nx\n",
    "                Be[:, 1, 1::2] = Ny\n",
    "                Be[:, 2, ::2] = Ny\n",
    "                Be[:, 2, 1::2] = Nx\n",
    "\n",
    "                eps_u = np.einsum(\"nij,nj -> ni\", Be, u[self.var])\n",
    "                eps_v = np.einsum(\"nij,nj -> ni\", Be, v[self.var])\n",
    "\n",
    "                # This is a fancy (and fast) way to compute the element matrices\n",
    "                scale = detJ * self.p * self.rhoE ** (self.p - 1.0)\n",
    "                dfdrhoE += np.einsum(\"n,ni,ij,nj -> n\", scale, eps_u, self.C, eps_v)\n",
    "\n",
    "        return dfdrhoE\n",
    "    \n",
    "    def mass_matrix_derivative(self, u, v):\n",
    "        \"\"\"\n",
    "        Compute dm/drhoE\n",
    "        \"\"\"\n",
    "\n",
    "        # Set the derivative we're about to compute\n",
    "        dmdrhoE = np.zeros(self.nelems)\n",
    "\n",
    "        # Assemble all of the the 8 x 8 element mass matrix\n",
    "        He = np.zeros((self.nelems, 2, 8))\n",
    "\n",
    "        for j in range(2):\n",
    "            for i in range(2):\n",
    "                xi = self.gauss_pts[i]\n",
    "                eta = self.gauss_pts[j]\n",
    "\n",
    "                # Evaluate the shape functions\n",
    "                N, _, _ = eval_shape_funcs(xi, eta)\n",
    "\n",
    "                # Evaluate the shape functions in physical coordinates\n",
    "                detJ, _, _ = eval_shape_funcs_gradient(xi, eta, self.xe, self.ye)\n",
    "\n",
    "                # Set the H matrix for each element\n",
    "                He[:, 0, ::2] = N\n",
    "                He[:, 1, 1::2] = N\n",
    "\n",
    "                vel_u = np.einsum(\"nij,nj -> ni\", He, u[self.var])\n",
    "                vel_v = np.einsum(\"nij,nj -> ni\", He, v[self.var])\n",
    "\n",
    "                # This is a fancy (and fast) way to compute the element matrices\n",
    "                scale = detJ * self.p * self.rho * (self.rhoE ** (self.p - 1.0))\n",
    "                dmdrhoE += np.einsum(\"n,ni,ni -> n\", scale, vel_u, vel_v)\n",
    "\n",
    "        return dmdrhoE\n",
    "    \n",
    "    def frequencies(self, A, k=5, sigma=0.0):\n",
    "        \"\"\"\n",
    "        Compute the k-th smallest natural frequencies\n",
    "\n",
    "        Parameters:\n",
    "            A: design variable\n",
    "            k: 1st to k-th smallest eigenvalues\n",
    "            \n",
    "        Return:\n",
    "            omega: the k-th smallest eigenvalues\n",
    "            phi: the eigenvectors corresponding to the k-th smallest eigenvalues\n",
    "        \"\"\"\n",
    "\n",
    "        self.rhoE = self._compute_rhoE(A)\n",
    "        K = self.assemble_stiffness_matrix(self.rhoE)\n",
    "        Kr = self.reduce_matrix(K)\n",
    "\n",
    "        M = self.assemble_mass_matrix(self.rhoE)\n",
    "        Mr = self.reduce_matrix(M)\n",
    "\n",
    "        # Find the eigenvalues closest to zero. This uses a shift and\n",
    "        # invert strategy around sigma = 0, which means that the largest\n",
    "        # magnitude values are closest to zero.\n",
    "        if k < len(self.reduced):\n",
    "            eigs, phir = sparse.linalg.eigsh(Kr, M=Mr, k=k, sigma=sigma,\n",
    "                                             which='LM', tol=1e-6)\n",
    "        else:\n",
    "            eigs, phir = scipy.linalg.eigh(Kr.todense(), b=Mr.todense())\n",
    "            k = len(eigs)\n",
    "\n",
    "        phi = np.zeros((self.nvars, k))\n",
    "        for i in range(k):\n",
    "            phi[self.reduced, i] = phir[:, i]\n",
    "\n",
    "        return np.sqrt(eigs), phi\n",
    "\n",
    "    def frequency_derivative(self, A, k=5):\n",
    "        \"\"\"\n",
    "        Compute the gradient of the smallest eigenvalues, assuming they are unique\n",
    "        \"\"\"\n",
    "        if k > len(self.reduced):\n",
    "            k = len(self.reduced)\n",
    "\n",
    "        omega, phi = self.frequencies(A, k=k)\n",
    "\n",
    "        omega_grad = []\n",
    "        for i in range(k):\n",
    "            kx = self.stiffness_matrix_derivative(phi[:,i], phi[:,i])\n",
    "            mx = self.mass_matrix_derivative(phi[:,i], phi[:,i])\n",
    "            grad = kx - mx*omega[i]**2  \n",
    "            domegadrhoE = (0.5/omega[i])*grad\n",
    "            domegadx = self._compute_rhoE_gradient(A, domegadrhoE)\n",
    "            omega_grad.append(domegadx)\n",
    "\n",
    "        return omega_grad\n",
    "\n",
    "    # def ks_min_eigenvalue(self, A, ks_rho=100.0, k=5):\n",
    "    #     \"\"\"\n",
    "    #     Compute the ks minimum eigenvalue\n",
    "    #     \"\"\"\n",
    "    #     if k > len(self.reduced):\n",
    "    #         k = len(self.reduced)\n",
    "\n",
    "    #     omega, phi = self.frequencies(A, k=k)\n",
    "    #     lamb = omega**2\n",
    "\n",
    "    #     c = np.min(lamb)\n",
    "    #     eta = np.exp(-ks_rho*(lamb - c))\n",
    "    #     a = np.sum(eta)\n",
    "    #     ks_min = c - np.log(a)/ks_rho\n",
    "    #     eta *= 1.0/a\n",
    "\n",
    "    #     # ks_grad = np.zeros(self.nelems)\n",
    "    #     ks_grad = np.zeros(self.nnodes)\n",
    "    #     for i in range(k):\n",
    "    #         kx = self.stiffness_matrix_derivative(phi[:,i], phi[:,i])\n",
    "    #         mx = self.mass_matrix_derivative(phi[:,i], phi[:,i])\n",
    "    #         dksdrhoE = eta[i]*(kx - mx*lamb[i]) # number of elements\n",
    "    #         dksdx = self._compute_rhoE_gradient(A, dksdrhoE) # back to number of nodes\n",
    "    #         ks_grad += dksdx\n",
    "\n",
    "    #     return ks_min, ks_grad\n",
    "    \n",
    "    def ks_min_eigenvalue(self, A, ks_rho=100.0, k=5):\n",
    "        \"\"\"\n",
    "        Compute the ks minimum eigenvalue and the gradient w.r.t. design variables dKS/dx\n",
    "        1st compute dKS/drhoE, then go to dKS/dx\n",
    "        \"\"\"\n",
    "        if k > len(self.reduced):\n",
    "            k = len(self.reduced)\n",
    "\n",
    "        omega, phi = self.frequencies(A, k=k)\n",
    "        lamb = omega**2\n",
    "\n",
    "        c = np.min(lamb)\n",
    "        eta = np.exp(-ks_rho*(lamb - c))\n",
    "        a = np.sum(eta)\n",
    "        ks_min = c - np.log(a)/ks_rho\n",
    "        eta *= 1.0/a\n",
    "\n",
    "        # ks_grad = np.zeros(self.nnodes)\n",
    "        dksdrhoE = np.zeros(self.nelems)\n",
    "        for i in range(k):\n",
    "            kx = self.stiffness_matrix_derivative(phi[:,i], phi[:,i])\n",
    "            mx = self.mass_matrix_derivative(phi[:,i], phi[:,i])\n",
    "            dksdrhoE += eta[i]*(kx - mx*lamb[i]) # number of elements\n",
    "        \n",
    "        ks_grad = self._compute_rhoE_gradient(A, dksdrhoE)\n",
    "\n",
    "        return ks_min, ks_grad\n",
    "    \n",
    "    def reduce_vector(self, forces):\n",
    "        \"\"\"\n",
    "        Eliminate essential boundary conditions from the vector\n",
    "        \"\"\"\n",
    "        return forces[self.reduced]\n",
    "\n",
    "    def reduce_matrix(self, matrix):\n",
    "        \"\"\"\n",
    "        Eliminate essential boundary conditions from the matrix\n",
    "        \"\"\"\n",
    "        temp = matrix[self.reduced, :]\n",
    "        return temp[:, self.reduced]\n",
    "\n",
    "    def _compute_rhoE(self, x):\n",
    "        # Apply the spatial/PDE filter\n",
    "        rho = self.fltr.apply_filter(x)\n",
    "\n",
    "        # Compute the element-based density values\n",
    "        rhoE = 0.25 * (\n",
    "            rho[self.conn[:, 0]]\n",
    "            + rho[self.conn[:, 1]]\n",
    "            + rho[self.conn[:, 2]]\n",
    "            + rho[self.conn[:, 3]]\n",
    "        )\n",
    "\n",
    "        return rhoE\n",
    "\n",
    "    def _compute_rhoE_gradient(self, x, dfdrhoE):\n",
    "        \"\"\"  \n",
    "        Go from df/drhoE to df/dx, as rhoE = F @ x where F is filter function\n",
    "        \"\"\"\n",
    "        # Add derivative contributions from the four nodes. np.add.at is used\n",
    "        # because the connectivity array may contain duplicate indices, so regular\n",
    "        # adding will not work.\n",
    "        dfdrho = np.zeros((self.nnodes))\n",
    "        contrib = 0.25 * dfdrhoE\n",
    "        for k in range(4):\n",
    "            np.add.at(dfdrho, self.conn[:, k], contrib)\n",
    "\n",
    "        # Compute the derivative\n",
    "        return self.fltr.apply_filter_gradient(dfdrho, x=x)\n",
    "\n",
    "    def compliance(self, x):\n",
    "        \"\"\"\n",
    "        Given the design variables x, find the compliance\n",
    "        \"\"\"\n",
    "\n",
    "        # Compute the element-based density values\n",
    "        self.rhoE = self._compute_rhoE(x)\n",
    "\n",
    "        # Form and solve the governing equations\n",
    "        K = self.assemble_stiffness_matrix(self.rhoE)\n",
    "        Kr = self.reduce_matrix(K)\n",
    "        fr = self.reduce_vector(self.f)\n",
    "\n",
    "        ur = sparse.linalg.spsolve(Kr, fr)\n",
    "\n",
    "        # Save the solution vector for later\n",
    "        self.u = np.zeros(self.nvars)\n",
    "        self.u[self.reduced] = ur\n",
    "\n",
    "        return ur.dot(fr)\n",
    "\n",
    "    def compliance_gradient(self, x):\n",
    "        \"\"\"\n",
    "        Compute the gradient of the compliance. Assume that the displacements have already been computed.\n",
    "        \"\"\"\n",
    "\n",
    "        # Compute the derivative of the compliance\n",
    "        dfdrhoE = -self.stiffness_matrix_derivative(self.u, self.u)\n",
    "\n",
    "        return self._compute_rhoE_gradient(x, dfdrhoE)\n",
    "\n",
    "    def compute_area(self, x):\n",
    "        \"\"\"Compute the area/volume of the structure\"\"\"\n",
    "\n",
    "        self.rhoE = self._compute_rhoE(x)\n",
    "\n",
    "        area = 0.0\n",
    "        for j in range(2):\n",
    "            for i in range(2):\n",
    "                xi = self.gauss_pts[i]\n",
    "                eta = self.gauss_pts[j]\n",
    "\n",
    "                # Evaluate the gradient of the shape functions in physical coordinates\n",
    "                detJ, Nx, Ny = eval_shape_funcs_gradient(xi, eta, self.xe, self.ye)\n",
    "\n",
    "                # Add the contributions to the area\n",
    "                area += np.dot(detJ, self.rhoE)\n",
    "\n",
    "        return area\n",
    "\n",
    "    def compute_area_gradient(self, x):\n",
    "        \"\"\"\n",
    "        This assumes that the mass is a function of\"\"\"\n",
    "\n",
    "        # The derivative of the mass w.r.t. rhoE\n",
    "        dAdrhoE = np.zeros(self.nelems)\n",
    "\n",
    "        for j in range(2):\n",
    "            for i in range(2):\n",
    "                xi = self.gauss_pts[i]\n",
    "                eta = self.gauss_pts[j]\n",
    "\n",
    "                # Evaluate the gradient of the shape functions in physical coordinates\n",
    "                detJ, Nx, Ny = eval_shape_funcs_gradient(xi, eta, self.xe, self.ye)\n",
    "\n",
    "                # Assuming rhoE is contant for each element\n",
    "                dAdrhoE[:] += detJ\n",
    "\n",
    "        return self._compute_rhoE_gradient(x, dAdrhoE)\n",
    "\n",
    "\n",
    "# class MassConstrainedCompliance:\n",
    "#     \"\"\"  \n",
    "#     Compliance minimization with a mass constraint\n",
    "#     \"\"\"\n",
    "#     def __init__(self, ps, area_fixed):\n",
    "#         self.ps = ps\n",
    "#         self.area_fixed = area_fixed\n",
    "\n",
    "#     def obj_con(self, x):\n",
    "#         fobj = self.ps.compliance(x)\n",
    "#         con = np.array([self.ps.compute_area(x) - self.area_fixed])  # <= 0.0\n",
    "\n",
    "#         return fobj, con\n",
    "\n",
    "#     def obj_con_grad(self, x):\n",
    "#         # objective gradient\n",
    "#         fgrad = self.ps.compliance_gradient(x)\n",
    "\n",
    "#         # constraint gradient 'A'\n",
    "#         # Up-convert to a 1 x nnodes numpy array\n",
    "#         A = self.ps.compute_area_gradient(x)[np.newaxis, :]\n",
    "\n",
    "#         return fgrad, A\n",
    "\n",
    "#     def _get_string(self, fd, ans, err):\n",
    "#         s = f\"Finite-difference: {fd:15.8} Answer: {ans:15.8} Relative err: {err:15.8}\"\n",
    "#         return s\n",
    "\n",
    "#     def check_gradient(self, x, p=None, dh=1e-6):\n",
    "#         \"\"\"Perform a finite-difference check along the direction p\"\"\"\n",
    "\n",
    "#         if p is None:\n",
    "#             p = np.random.uniform(size=x.shape)\n",
    "\n",
    "#         fobj, con = self.obj_con(x)\n",
    "#         fgrad, A = self.obj_con_grad(x)\n",
    "\n",
    "#         fobj1, con1 = self.obj_con(x + dh * p)\n",
    "\n",
    "#         fd = (fobj1 - fobj) / dh\n",
    "#         ans = np.dot(fgrad, p)\n",
    "#         rel_err = (ans - fd) / fd\n",
    "#         print(\"Objective: \")\n",
    "#         print(self._get_string(fd, ans, rel_err))\n",
    "\n",
    "#         for i in range(len(con)):\n",
    "#             fd = (con1[i] - con[i]) / dh\n",
    "#             ans = np.dot(A[i, :], p)\n",
    "#             rel_err = (ans - fd) / fd\n",
    "#             print(f\"Constraint {i}\")\n",
    "#             print(self._get_string(fd, ans, rel_err))\n",
    "\n",
    "\n",
    "class MassFreqConstrainedCompliance:\n",
    "    \"\"\"  \n",
    "    Compliance minimization with a mass and frequency constraint\n",
    "    \"\"\"\n",
    "    def __init__(self, ps, area_fixed, min_freq):\n",
    "        self.ps = ps\n",
    "        self.area_fixed = area_fixed\n",
    "        self.min_freq = min_freq\n",
    "\n",
    "    def obj_con(self, x):\n",
    "        fobj = self.ps.compliance(x)\n",
    "        con1 = np.array([self.ps.compute_area(x) - self.area_fixed])  # <= 0.0\n",
    "        con2 = np.array([self.min_freq-self.ps.ks_min_eigenvalue(x, k=5)[0]]) \n",
    "        con = [con1, con2]\n",
    "        return fobj, con\n",
    "\n",
    "    def obj_con_grad(self, x):\n",
    "        # objective gradient\n",
    "        fgrad = self.ps.compliance_gradient(x)\n",
    "\n",
    "        # constraint gradient 'A'\n",
    "        # Up-convert to a 1 x nnodes numpy array\n",
    "        dcdx1 = self.ps.compute_area_gradient(x)[np.newaxis, :]\n",
    "        dcdx2 = self.ps.ks_min_eigenvalue(x, k=5)[1]\n",
    "        A = np.vstack((dcdx1, -dcdx2))\n",
    "        return fgrad, A\n",
    "\n",
    "    def _get_string(self, fd, ans, err):\n",
    "        fd_val = np.asarray(fd).item()\n",
    "        ans_val = np.asarray(ans).item()\n",
    "        err_val = np.asarray(err).item()\n",
    "        s = f\"Finite-difference: {fd_val:15.8} Answer: {ans_val:15.8} Relative err: {err_val:15.8}\"\n",
    "        return s\n",
    "\n",
    "    def check_gradient(self, x, p=None, dh=1e-6):\n",
    "        \"\"\"Perform a finite-difference check along the direction p\"\"\"\n",
    "\n",
    "        if p is None:\n",
    "            p = np.random.uniform(size=x.shape)\n",
    "\n",
    "        fobj, con = self.obj_con(x)\n",
    "        fgrad, A = self.obj_con_grad(x)\n",
    "\n",
    "        fobj1, con1 = self.obj_con(x + dh * p)\n",
    "\n",
    "        fd = (fobj1 - fobj) / dh\n",
    "        ans = np.dot(fgrad, p)\n",
    "        rel_err = (ans - fd) / fd\n",
    "        print(\"Objective: \")\n",
    "        print(self._get_string(fd, ans, rel_err))\n",
    "\n",
    "        for i in range(len(con)):\n",
    "            fd = (con1[i] - con[i]) / dh\n",
    "            ans = np.dot(A[i, :], p)\n",
    "            print(\"A:\", A[i, :])\n",
    "            print(\"p:\", p)\n",
    "            rel_err = (ans - fd) / fd\n",
    "            print(f\"Constraint {i}\")\n",
    "            print(self._get_string(fd, ans, rel_err))\n",
    "\n",
    "\n",
    "# Set the dimensions of the design domain\n",
    "Lx = 5.0\n",
    "Ly = 2.0\n",
    "nx = 125\n",
    "ny = 50\n",
    "\n",
    "# Set the filter radius\n",
    "r0 = 2 * (Lx / nx)\n",
    "\n",
    "# Set the number of elements and nodes\n",
    "nelems = nx * ny\n",
    "nnodes = (nx + 1) * (ny + 1)\n",
    "\n",
    "# Set locations x/y locations along each edge and node numbers\n",
    "x = np.linspace(0, Lx, nx + 1)\n",
    "y = np.linspace(0, Ly, ny + 1)\n",
    "nodes = np.arange(0, (nx + 1) * (ny + 1)).reshape((nx + 1, ny + 1))\n",
    "\n",
    "# Set the node locations\n",
    "X = np.zeros((nnodes, 2))\n",
    "for j in range(ny + 1):\n",
    "    for i in range(nx + 1):\n",
    "        X[nodes[i, j], 0] = x[i]\n",
    "        X[nodes[i, j], 1] = y[j]\n",
    "\n",
    "# Set the connectivity\n",
    "conn = np.zeros((nelems, 4), dtype=int)\n",
    "for j in range(ny):\n",
    "    for i in range(nx):\n",
    "        conn[i + j * nx, 0] = nodes[i, j]\n",
    "        conn[i + j * nx, 1] = nodes[i + 1, j]\n",
    "        conn[i + j * nx, 2] = nodes[i + 1, j + 1]\n",
    "        conn[i + j * nx, 3] = nodes[i, j + 1]\n",
    "\n",
    "# Set boundary conditions for the finite-element problem\n",
    "bcs = {}\n",
    "for j in range(ny):\n",
    "    bcs[nodes[0, j]] = [0, 1]\n",
    "\n",
    "# print\n",
    "# number of elements and number of nodes\n",
    "print(\"Number of elements:\", nelems)\n",
    "print(\"Number of nodes:\", nnodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6a836f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective: \n",
      "Finite-difference:       -464.3045 Answer:      -464.30565 Relative err:   2.4791606e-06\n",
      "A: [0.00054604 0.00085615 0.00093496 ... 0.00093496 0.00085615 0.00054604]\n",
      "p: [0.69253473 0.29428679 0.94278439 ... 0.66855308 0.41666802 0.87492277]\n",
      "Constraint 0\n",
      "Finite-difference:        5.033078 Answer:       5.0330779 Relative err:  -7.7684165e-09\n",
      "A: [-3.67764086e-04 -4.89567679e-04 -4.10053749e-04 ... -7.15063388e-09\n",
      " -2.64105432e-09 -6.30334872e-10]\n",
      "p: [0.69253473 0.29428679 0.94278439 ... 0.66855308 0.41666802 0.87492277]\n",
      "Constraint 1\n",
      "Finite-difference:   0.00062686212 Answer:     -0.19965551 Relative err:      -319.49988\n"
     ]
    }
   ],
   "source": [
    "# Set the load\n",
    "P = 1.0\n",
    "forces = {}\n",
    "forces[nodes[-1, 0]] = [0, -P]\n",
    "\n",
    "# Create a spatial filter\n",
    "fltr = NodeFilter(conn, X, r0=r0, ftype=\"spatial\")\n",
    "\n",
    "# Create the plane stress problem\n",
    "ps = PlaneStress(conn, X, bcs, forces, fltr=fltr)\n",
    "\n",
    "# Create the optimization object\n",
    "area_fraction = 0.4\n",
    "opt = MassFreqConstrainedCompliance(ps, area_fraction * Lx * Ly, min_freq=50.0)\n",
    "\n",
    "lb = 1e-3 * np.ones(nnodes)\n",
    "ub = np.ones(nnodes)\n",
    "x_init = area_fraction * np.ones(nnodes)\n",
    "\n",
    "opt.check_gradient(x_init)\n",
    "\n",
    "# mma = MMA(nnodes, 1, x_init, lb, ub, opt.obj_con, opt.obj_con_grad)\n",
    "\n",
    "# for i in range(50):\n",
    "#     mma.update()\n",
    "\n",
    "# fltr.plot(fltr.apply(mma.x))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b8d31c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SciML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
